{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic sign recongtion project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By Yaozhong Zhang  July 12, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "training_file = \"train.p\"\n",
    "validation_file = \"valid.p\"\n",
    "testing_file = \"test.p\"\n",
    "\n",
    "with open(training_file,mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file,mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file,mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'],test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of validation examples = 4410\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Provide a basic summary of the data set\n",
    "\n",
    "n_train = len(X_train)\n",
    "n_validation = len(X_valid)\n",
    "n_test = len(X_test)\n",
    "\n",
    "image_shape = X_train[0].shape\n",
    "#n_classes = \n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of validation examples =\", n_validation)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "#print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize data\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the training data\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement LeNet-5\n",
    "\n",
    "\"\"\"\n",
    "Architecture\n",
    "Layer 1: Convolutional. The output shape should be 28x28x6.\n",
    "\n",
    "Activation. Your choice of activation function.\n",
    "\n",
    "Pooling. The output shape should be 14x14x6.\n",
    "\n",
    "Layer 2: Convolutional. The output shape should be 10x10x16.\n",
    "\n",
    "Activation. Your choice of activation function.\n",
    "\n",
    "Pooling. The output shape should be 5x5x16.\n",
    "\n",
    "Flatten. Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. The easiest way to do is by using tf.contrib.layers.flatten, which is already imported for you.\n",
    "\n",
    "Layer 3: Fully Connected. This should have 120 outputs.\n",
    "\n",
    "Activation. Your choice of activation function.\n",
    "\n",
    "Layer 4: Fully Connected. This should have 84 outputs.\n",
    "\n",
    "Activation. Your choice of activation function.\n",
    "\n",
    "Layer 5: Fully Connected (Logits). This should have 10 outputs.\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x):\n",
    "    \n",
    "    #Layer 1 convolutional Input 32x32x3\n",
    "    conv1_W = tf.Variable(tf.truncated_normal([5,5,3,6]))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1 = tf.nn.conv2d(x,conv1_W,strides = [1,1,1,1],padding = 'VALID')\n",
    "    conv1 = tf.nn.bias_add(conv1,conv1_b)\n",
    "    \n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    \n",
    "    #Pooling Input 28x28x6\n",
    "    conv1 = tf.nn.max_pool(conv1,ksize = [1,2,2,1],strides=[1,2,2,1],padding = 'SAME')\n",
    "    \n",
    "    #Layer 2 convolutional Input 14x14x6\n",
    "    conv2_W = tf.Variable(tf.truncated_normal([5,5,6,16]))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2 = tf.nn.conv2d(conv1,conv2_W,strides = [1,1,1,1],padding = 'VALID')\n",
    "    conv2 = tf.nn.bias_add(conv2,conv2_b)\n",
    "    \n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    \n",
    "    #Pooling Input 10x10x16\n",
    "    conv2 = tf.nn.max_pool(conv2,ksize=[1,2,2,1],strides=[1,2,2,1],padding = 'SAME')\n",
    "    \n",
    "    #Flatten Input 5x5x16\n",
    "    flat = flatten(conv2)\n",
    "    \n",
    "    #Layer 3 Fully connectted Input 400\n",
    "    fc1_W = tf.Variable(tf.truncated_normal([400,120]))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1 = tf.matmul(flat,fc1_W) + fc1_b\n",
    "    \n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "    #Layer 4 Fully connectted Input 120\n",
    "    fc2_W = tf.Variable(tf.truncated_normal([120,84]))\n",
    "    fc2_b = tf.Variable(tf.zeros(84))\n",
    "    fc2 = tf.matmul(fc1,fc2_W) + fc2_b\n",
    "    \n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "    \n",
    "    #Layer 5 Fully connectted Input 84\n",
    "    fc3_W = tf.Variable(tf.truncated_normal([84,43]))\n",
    "    fc3_b = tf.Variable(tf.zeros(43))\n",
    "    fc3 = tf.matmul(fc2,fc3_W) + fc3_b\n",
    "    \n",
    "    logits = fc3\n",
    "    \n",
    "    return logits\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set features and labels\n",
    "\n",
    "x = tf.placeholder(tf.float32,(None,32,32,3))\n",
    "y = tf.placeholder(tf.int32,(None))\n",
    "one_hot_y = tf.one_hot(y,43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training pipeline\n",
    "\n",
    "rate = 0.001\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels = one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34799\n",
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.054\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.043\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.041\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    print(num_examples)\n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_valid, y_valid)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
