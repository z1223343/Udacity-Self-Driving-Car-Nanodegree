{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic sign recongtion project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By Yaozhong Zhang  July 12, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "training_file = \"train.p\"\n",
    "validation_file = \"valid.p\"\n",
    "testing_file = \"test.p\"\n",
    "\n",
    "with open(training_file,mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file,mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file,mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'],test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 34799\n",
      "Number of validation examples = 4410\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Provide a basic summary of the data set\n",
    "\n",
    "n_train = len(X_train)\n",
    "n_validation = len(X_valid)\n",
    "n_test = len(X_test)\n",
    "\n",
    "image_shape = X_train[0].shape\n",
    "n_classes = len(set(y_train))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of validation examples =\", n_validation)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAERNJREFUeJztnEuMHVdax3+nqu6z7719++Vud7v9zKPtxCQQkhlmNAIESEMEGliAmAUCCSlsRgKJBSNWLGcBbJGCGInFSCPQgJjFIBQhgoiEItujZJKMJ7GT2E770e7u2933Xc/D4vuquuPx49rtqVjx/aRWVdc9dc6pr/7ne58y1lrGlA85n/UEHicaMztHGjM7RxozO0caMztHGjM7RxozO0faF7ONMV81xrxvjLlojPnmw5rU55XMgzo1xhgX+AD4DWAVOAN83Vr744c3vc8Xefu49yXgorX2IwBjzHeBrwF3ZHahWLSlcpkkSUiSBACbyMt2HCMT8gokSQxAHMvR7OnDpvcpSPZCJcWNAYzeVHDlERMr90V6/94bkrsAznUdHMf59Ji3HKMoJkkSc/sedmk/zF4CPtnz/yrwhVsbGWNeAV4BKJbKPPfiF+gPOvR7AwACPwCgWq0AMD0zx7DfAaC9swOAi8WoxPMHfQDCwAcgwSV9zCSMtD14nlxcbM4C0B30ANjyB1lfcRRKnzqHOLFY0pcvbRqNGhMVmZsfSvswlPZRHIONWV/fGolh+2H27d7kT0HEWvsq8CrARL1uo9DHs1AgRa0wyCTyADutTQY9YYznpN0l+L60i0JlcpIi1RLHymSFs3EdkkjuvbktjAjs7opwC/LYcaz9O3J/vVbN+kj0UYrlCp3BUMf89ON5rovjuBhzT1BL+5Fa3Z5WgeU9/x8Crt3tBmPA8cBxqtQLBbmYyIMGKRNxcFWkoAzy/YAgkHZFfbA42V3C1sqLK5XLAMw0msSK/PXtbQBCFUluoUC1MQmAV3BlTFcZW53Mxo5CYfBg6BMq8jNRpy/LGIit/WmE3YH2Y42cAZ40xhwzxhSBPwC+v4/+Pvf0wMi21kbGmG8A/4mIyW9ba9+7602JxfoRvV6XOBik/QAQqd7yPA+bol0RFYYhxtGpuoIux8h9bmIxXhGAleMnAHhq7gA3bq4BYBRON7dE/sfW0lUxVa7ISmgo0uMoot+XeSWRzCGMYlCFbVPlkCpUR+Y/qkW3HzGCtfYHwA/208fjRPti9v2S47rU63WmKlXCtsjS/lBk445aEhhLEO4iGsBiKBZLAJRLIusTZCk43oCZmQUAvnjiaQC2L/yYAzpmMDMtfUWCzkEUY12B+7DXlaNVPWAtrkrWKEoVsc0U4K7JJ2MbY8DY25gFd3j+0ZqN6WFQrshuTjb4rd/8Kk474H//5zUAOsFNAKJYUByHPpHKy0hNuigBa0XORqEg21NrplAscWRhHoDg5g0ABlc/odSYAmC+KfJ4a6oJwHpvkFkVgSLc9wXFcZSI7cyumee6Tgbc1PY2pM4QI6Macmb2RL3Jl371t3n3zP9xwxfHZWsgSzmzYeOYojIhUFPe2JiKrsFCQb05Nb+mZ+dYqtUB6J9/Wxr5AWGnDUBRf1ueE8ESVTr0OuIYDZTJrmrROIkzTzMVGXEcZ3a5o/MyqUK0u/b+KDQWIzlSrsje2trhu//yH3z84TustcSzi1VkGFVStVo9c7ULZUFNGAZEvijSdNmmTlujVqKw0wKgsyVK17gGox4qnR1tV5P+HZeNoZh3w6Eg21FwRkmSoa+gDo9jDEnmZMkhXYQGizOa8yh9jd50TPulXJHd6bR44/XvsLnRIlF3Wi040qCZH5OZZoHKUteDZnVCzkviwFRrEhx6cmae4F2V1Yqy+ZWTuOr83Pz4ktynbnuzVKSkg7Z1VaUxEkuCVahm8Q7HZDI6lee3xBpHfv5cmZ1EEZ2tFoR+thbj1K5VReMEPv5QzuNYlZXrYHVZB4lYLfM1UXjO9jaDLREjlbk5AJ7+9ZcJOnKtp0zutkWcTJXmmKuKSOlo5NFXOeKQZIrRTS0P19llss4nlWEuhoSEEeNQYzGSJ+WL7MTiD3xMYtm19ESRReotdsOAckliFhNqtvnDHv2BoLBWkGtHqmI3Jxd+glH5sXjq5wCYPfksflsU8IErlwDonz0DgNfvs6D99jQGs94WMzEMwwzZxklxaEjlUypEHP3fGoNrR9eQY2TnSLki22Ax1hIlu/HoNM2VqLdorSEpqrLU30q1iUzGzzUl1lHRzEu7tU55egaAg78giSKvXsNobHv+WUH79pXLclxbp6HRvgM1UbqbGqex1uJ5gr8wTOeza+plqHf3pNPGpt+jSbki27IHPSrrjAb7PDdNVcWYVDpawUK5MklR3fQn5iQOEn58QZpEEXMrpwCYOv6kXHM9HFdiJ7MnVgDYXrkIQGdjA7qyKmYaYpUcmJGVsdPtZjok1MyQdJiuPrVaUk/GcUiShFELFHJldsHzmJudYn6yyM0diY1c35DYSLpEPdfFpuHTWLzGze2IQ3PCkLIvcY3ehgSwSs0mh1/8ovw22QDAmD0B/boEpKZOPgdA4+MPaV1eBWBSxcjylLTpBQP6bRnTVVs/2aPMs1BrWhGAvWtm/lYai5EcKVdkF4suy4eaFKMBxUTrOQJZ7tu67B2viKumX6geXsXEHFeHJbh+Fdg1FRefWuHAUyIqrCq3xMasXZN2586/C8ChKVkZcytP01mTUGyiJl+zJOUOs7U6URB/auzBwM/QmyUPUqWOxGFGVZJjZOdI+Zp+jkdxYoZr6+s0SoKg55+oAtDqCFputGO2FV1eSVJhhw8ssOAJ8tuayC1qFG/5hZco6HkqPpMo5pIq0KsXJAd99Jd+GYDpJ59l6yMxA9c+EKVZHEicZqHWpK/1KTfVzY+SJFOMmVuexU/ErR/V+suV2VEUsdnaorWxRVDWLHkigaUglAfqDgb4aQwilDYzlQqhig8bSH5y9uSzANSPPEHPF5FSNVrPEVsqmnGfmjwIwIVLUtKyUZ2gOL8EQFn79NXObk5UqWuu85ra2XEUZ4rR9dxbnsgQx6NbI2MxkiPliuxa0fKVxZCLhRLdnqAxza6vtWUpB4kDqvwOzQsqF41He+26TLgqYmfyqacAeOO9HzE1K8rztGbX3373HG+dOwfA1auC6KLWEp5+5hTNCemjtnQIgOFPPgDAtNtMFoUl1aKIreFwiKuKN0V4agpGcYxNkpHrRsbIzpFyRfZktcjLLy5y5v11PmwJoiNVSHNTgryr2wOarjgbz554AoD+hVVirVSaOS2xjtrhIwC0zp+nXpR7z7wlSYSk1+ErL7wEwGu91wEo1iRKuLR8jOm69O/pcbguDlJ3p01zWlbJYlMdncGAoeqE1JPM4jo2ua+KqHsi2xizbIz5b2PMeWPMe8aYP9Pr08aY14wxF/Q4NdKIjzGNguwI+Atr7Q+NMXXgnDHmNeCPgf+y1n5Lt3h8E/jLu3VUrBRZPnmEf3t7kwtrIqNXpsRqWGoKOmfnpmkW5NztC+pvXF/F1Sjeskb2CpOL0mnwNmc1LbZ87CgAX3rpyxRCWQnlc9JXpKicnV3g2DEpvh00Be3bq1Jm3nnzTQp9iZvMVkSu36xW8QPJ8qTOjTG7pQx2T7z7XnRPZltrrwPX9bxjjDmPFMJ/DfgVbfZPwOvcg9lJFDFsbeH4MJDQCFtqTfURk64b9TmyKDEO9xNRimGvy7QqxOLycQDOvicKcPXKJww1ZrSibUpuQhILA6oTIio0187Gzg6LkSjGqirWhVPPANC69BHb1zcAaCqzD03P0degVG/w6WJQPINN7M8mLWaMOQr8PPAmMK8vIn0hB+5wzyvGmLPGmLMtDfI8rjSygjTG1IDvAX9urW2PWm2/d+fBycNTdvXyDu2hz05flM55heV6T15EeaLK4UmBe1vjG8YrcOh5UXjVpjgdp1YkHhLtbPPOpUsAlMriSUbW0O9Lf42mxETqE3Lf9RtXiLR4/sRRUbKTR2VFzK+corvxBgBxR5bedL1GQ7d5pMhOTT/PdcGxI+88GAnZxpgCwujvWGv/VS+vGWMO6u8HgZsjjfgY0z2RbeS1/SNw3lr7d3t++j7wR8C39Pjv9+orCOGTNUu7FxIoPPphmmqSqRw7eBi0NCHoSKx78ugxDp5+AYCZg6Lc6pEg9+qli6wYLYYcSvv1a6t4em1CY9anVqRQvrW5yY3tdQB2tiTxO7ss7vv8ydO0Ll8C4OaHHwPQKJc5qAniLa0f7GuNIHb0Oj8YTYx8GfhD4B1jzFt67a8QJv+zMeZPgCvA793XyI8hjWKNvMGdbZtfu5/BtvyI713Y5PKNLn1fd4s5Ip+ntKR3qVZn8KFE4xwN/Cydfo6JBdG/sZYYJDqlxswBFpaOAXD4kO6ncg0XL4gLXlX3fnpBfltcPsZxrfFLSyY8HWf6yHGWnpEAV/u6uPlhr8vClJQd93QOq5uy8vwgzLI2o1CuHuRwGPH+hU063T6Rbp0zGnc4NSXeorvVIuxIFK6xJAxaPv0CTlHs8XTlupp8mGw0mFDvMN2dEEU+RY1xHD0sfRRScy1KqKTYUa800PoRwoTatOximJiUhML65SuU1Hycq8hxwxNxMhj691WfPY6N5Ej5Jnwdh/lqiSkH1jXat7Qgkb2VWfH2N8+dBU07VdVs21pdY2f90yXGse678Qc9+uqyXA/S6iqfWBXothZsruqemjAMsqhiEqU7dnXXQxwTqck3WBeHKgl84h1ZafUpqVmZVoXZDUKicE8W/h40RnaOlCuyPddhrlFjpzqBPxRkHpzXmPKmuMnD7a1M6Vw7L98cuPr++zhZbXEal0hrS3b3m+8G3yxe6mik17IPC1hSfW9vMd32bpFJjwaINV5SUiU+3ZBwwrVWi+A+tnnkymwwJHgYFyoTEpxPldOOMjvGgivWgUnS0GaETfel61rMNgMYJyuCTPRH6zoYtTC8tPQ3u9EBtYCMjuOmR88jTsdOv8SAIdYakmJTmFzV/fAF1+C5zrhk+FGkfDedWkslCSl4Rdyy2L9xWv20KCZXfW4WENSnCVbXcwg1bBdYVZDpboA4yUp50yUd2XA3wI+rRyFrds9dbe/pRtbYcXDTbdu6v3un28niLMOWZOX9Xlvvc5lulGhpJv6ezz9SqzE9FPoMCivBhhE20b2IRd34qRWW69sDOj394IsizhjY3BaTLFSTMZXBSRwTpNuuFbLViSolTx4t1NKHIErb2OwzF9MVcZR6ugq6QZQVuqcmpkOCpzUr6b7JdI9NrV6W1TeW2Y8e5WyNCLpdx1DWmHJrKMe+lvFudzoMB4pGRXaYRHR25HfUiSiVxTUPwjDbdu0oAovFCo2a6IRuRyyHvhbPu45DXXfsTuoW7vUtWTX9KMm2TJfU3S9UyhRUv6RWTPoxGc8tQ2Sy8ud7Ub7MNoDj4BtoqeN1oy1MGKYppyjJaqQLmmDo+UPCoZw3NEaSbZLbYyu7XsqgCSrZfhwRVzZJP5MUM6Xb+1oaG+lo9tw4Dk5mn4uoCIbDrFY7Ta05yvSoYIgDxhVRjyI98Hf9HmgwY9aBHrCR26APTrOMPs8j1tq5ezXKldkAxpiz1tpfzHXQB6CfxTzHYiRHGjM7R/osmP3qZzDmg9BDn2fuMvtxprEYyZFyY/aj/K3tu1Tq/rUx5qox5i39e3lf4+QhRh71b21rRdfBvZW6wO8Avw90rbV/8zDGyQvZ2be2rbUBkH5r+5Ega+11a+0P9bwDpJW6D5XyYvbtvrX90B/mYdAtlboA3zDG/MgY8+39FvznxeyRvrX9WdOtlbrA3wMngOeRGvW/3U//eTH7vr+1nTfdrlLXWrtmrY2thBb/ARGHD0x5MfuR/tb2nSp105Jopd8F3t3POLnEsx/oW9v50p0qdb9ujHkeEXmXgD/dzyBjDzJHGnuQOdKY2TnSmNk50pjZOdKY2TnSmNk50pjZOdKY2TnS/wNIU49YTDy2RwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize data\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process and model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization!!!!!!!!!\n",
    "\n",
    "X_train = (np.float32(X_train)-128)/128\n",
    "X_valid = (np.float32(X_valid)-128)/128\n",
    "X_test = (np.float32(X_test)-128)/128\n",
    "\n",
    "#print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the training data\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement LeNet-5\n",
    "\n",
    "\"\"\"\n",
    "Architecture\n",
    "Layer 1: Convolutional. The output shape should be 28x28x6.\n",
    "\n",
    "Activation. Your choice of activation function.\n",
    "\n",
    "Pooling. The output shape should be 14x14x6.\n",
    "\n",
    "Layer 2: Convolutional. The output shape should be 10x10x16.\n",
    "\n",
    "Activation. Your choice of activation function.\n",
    "\n",
    "Pooling. The output shape should be 5x5x16.\n",
    "\n",
    "Flatten. Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. The easiest way to do is by using tf.contrib.layers.flatten, which is already imported for you.\n",
    "\n",
    "Layer 3: Fully Connected. This should have 120 outputs.\n",
    "\n",
    "Activation. Your choice of activation function.\n",
    "\n",
    "Layer 4: Fully Connected. This should have 84 outputs.\n",
    "\n",
    "Activation. Your choice of activation function.\n",
    "\n",
    "Layer 5: Fully Connected (Logits). This should have 10 outputs.\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x,keep_prob):\n",
    "    \n",
    "    mu = 0\n",
    "    sigma = 0.11\n",
    "    #Layer 1 convolutional Input 32x32x3\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5,5,3,6),mean= mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1 = tf.nn.conv2d(x,conv1_W,strides = [1,1,1,1],padding = 'VALID')\n",
    "    conv1 = tf.nn.bias_add(conv1,conv1_b)\n",
    "    \n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    \n",
    "    #Pooling Input 28x28x6\n",
    "    conv1 = tf.nn.max_pool(conv1,ksize = [1,2,2,1],strides=[1,2,2,1],padding = 'SAME')\n",
    "    \n",
    "    #Layer 2 convolutional Input 14x14x6\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2 = tf.nn.conv2d(conv1,conv2_W,strides = [1,1,1,1],padding = 'VALID')\n",
    "    conv2 = tf.nn.bias_add(conv2,conv2_b)\n",
    "    \n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    \n",
    "    #Pooling Input 10x10x16\n",
    "    conv2 = tf.nn.max_pool(conv2,ksize=[1,2,2,1],strides=[1,2,2,1],padding = 'SAME')\n",
    "    \n",
    "    #Flatten Input 5x5x16\n",
    "    flat = flatten(conv2)\n",
    "    \n",
    "    #Layer 3 Fully connectted Input 400\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1 = tf.matmul(flat,fc1_W) + fc1_b\n",
    "    \n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1,keep_prob)\n",
    "    \n",
    "    #Layer 4 Fully connectted Input 120\n",
    "    fc2_W = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    fc2_b = tf.Variable(tf.zeros(84))\n",
    "    fc2 = tf.matmul(fc1,fc2_W) + fc2_b\n",
    "    \n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "    fc2 = tf.nn.dropout(fc2,keep_prob)\n",
    "    \n",
    "    #Layer 5 Fully connectted Input 84\n",
    "    fc3_W = tf.Variable(tf.truncated_normal(shape=(84, 43), mean = mu, stddev = sigma))\n",
    "    fc3_b = tf.Variable(tf.zeros(43))\n",
    "    fc3 = tf.matmul(fc2,fc3_W) + fc3_b\n",
    "    \n",
    "    logits = fc3\n",
    "    \n",
    "    return logits\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set features and labels\n",
    "\n",
    "x = tf.placeholder(tf.float32,(None,32,32,3))\n",
    "y = tf.placeholder(tf.int32,(None))\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "one_hot_y = tf.one_hot(y,43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training pipeline\n",
    "\n",
    "rate = 0.0008\n",
    "\n",
    "logits = LeNet(x,keep_prob)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels = one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, keep_prob:1.0})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.550\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.778\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.836\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.880\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.891\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.906\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.913\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.931\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.937\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.930\n",
      "\n",
      "EPOCH 11 ...\n",
      "Validation Accuracy = 0.940\n",
      "\n",
      "EPOCH 12 ...\n",
      "Validation Accuracy = 0.935\n",
      "\n",
      "EPOCH 13 ...\n",
      "Validation Accuracy = 0.942\n",
      "\n",
      "EPOCH 14 ...\n",
      "Validation Accuracy = 0.944\n",
      "\n",
      "EPOCH 15 ...\n",
      "Validation Accuracy = 0.941\n",
      "\n",
      "EPOCH 16 ...\n",
      "Validation Accuracy = 0.945\n",
      "\n",
      "EPOCH 17 ...\n",
      "Validation Accuracy = 0.949\n",
      "\n",
      "EPOCH 18 ...\n",
      "Validation Accuracy = 0.948\n",
      "\n",
      "EPOCH 19 ...\n",
      "Validation Accuracy = 0.957\n",
      "\n",
      "EPOCH 20 ...\n",
      "Validation Accuracy = 0.953\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob:0.5})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_valid, y_valid)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\lenet\n",
      "Test Accuracy = 0.937\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model on new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and output the images\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
